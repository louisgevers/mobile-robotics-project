{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of Mobile Robotics: Project Report\n",
    "\n",
    "Authors:\n",
    "Louis Gevers, Paul Blossier, Zing\n",
    "Shawn Tan, NaÃ«l Dillenbourg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Robot Environment\n",
    "\n",
    "The robot has to navigate a square environment on a white sheet, where it has to reach a blue square while avoiding the red ones, from wherever it is released.\n",
    "We make use of ArUco markers, whose detection is robust, fast, and simple [1].\n",
    "Four markers are used to denote the corners of the environment, and a fifth one is put on the robot to obtain the relative position and orientation of the robot with respect to the corners.\n",
    "We first used small colored squares, but as we will show in the vision section, we have to choose the correct values to detect these colours, which can change with different lighting conditions.\n",
    "We therefore chose to only calibrate for the goal and obstacles, blue and red squares respectively, and not the corners and robot position, which use ArUco markers and therefore do not need adjustements with different lighting.\n",
    "\n",
    "The environment for this project has two types of obstacles:\n",
    "1. Permanent obstacles which are accounted for in the path planning and detected by our vision module (the red squares).\n",
    "2. Temporary obstacles which we cannot account for during path planning. These are detected by the local navigation module that takes control when an object is close enough to the proximity sensors.\n",
    "\n",
    "We chose a sparse, non-discrete environment, as we were more comfortable for the Thymio to do long straight lines with occasional small turns rather than the many rotations with small advancements required in a grid-like environment (it would also be faster).\n",
    "As we went on with the project we discovered that this brings its challenges, as it is much harder to update the map when seeing obstacles and the control is not as straightforward.\n",
    "If we were to do the project again we would probably go for a grid-like structure for easier map updates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Project Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Project dependencies\n",
    "\n",
    "Using best development practices, we have our python dependencies in a `requirements.txt` file.\n",
    "Furthermore, we have all of our Python source code in different files under the `src` folder.\n",
    "To use them in the notebook we install them with `pip` as well, with the `-e` flag to capture potential edits.\n",
    "(We use the `import sys` method to make sure pip installs it in the currently used Jupyter kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# This cell can be pretty noisy, so we hide the output. If you want to see it remove the %%capture magic keyword\n",
    "import sys\n",
    "# Install dependencies\n",
    "!{sys.executable} -m pip install -r \"../requirements.txt\"\n",
    "# Install the project source files (i.e. the src directory specified in the root-level setup.py)\n",
    "!{sys.executable} -m pip install -e \"../\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Project models\n",
    "\n",
    "To make integration as easy as possible while allowing us to work on the different parts independently, we started the project by agreeing on common datastructures to represent sensor data, robot pose, obstacles, etc..\n",
    "All these models can be found in the `src/model.py` file as a separate class.\n",
    "Using these models we can define what each component of the project has to implement and what it needs.\n",
    "For example, the path planning component needs a representation of the obstacles, the goal, and the intial position of the robot, and returns a path.\n",
    "\n",
    "The cell below shows how to create each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the script\n",
    "from src import model\n",
    "\n",
    "### Modeling the world of the robot\n",
    "# A simple 2D point, can be used for a position or in sequence for a path\n",
    "point = model.Point(x=0, y=0)\n",
    "# Representation of a robot, both position as a point and angle in radians\n",
    "robot = model.Robot(position=point, angle=0)\n",
    "# Representation of an obstacle, which contains an arbitrary number of points\n",
    "obstacle = model.Obstacle(corners=[model.Point(x=0,y=0), model.Point(x=1, y=0), model.Point(x=5,y=10)])\n",
    "# Representation of the world state, which contains a robot, a goal, and a list of obstacles\n",
    "world = model.World(robot=robot, goal=point, obstacles=[obstacle])\n",
    "\n",
    "### Modeling the data from the robot\n",
    "# Speed of the robot wheels\n",
    "speed = model.MotorSpeed(left=100, right=100)\n",
    "# Horizontal IR sensor values\n",
    "horizontal = model.HorizontalSensor([0, 0, 0, 0, 0]) # Initialized with a list, representation from the thymio\n",
    "horizontal.center # Can access individual values with names properties\n",
    "# Ground IR sensor values\n",
    "ground = model.GroundSensor([0, 0])\n",
    "ground.left\n",
    "# Model containing all the relevant sensor values from the Thymio\n",
    "sensor_data = model.SensorReading(horizontal=horizontal, ground=ground, motor=speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Thymio abstraction\n",
    "\n",
    "We made our own Thymio class to send motor commands and obtain sensor values from the Thymio without worrying about the exact `tdmclient` implementation.\n",
    "This abstraction allowed us to focus on our algorithms using the predefined models, without having to worry about the exact Thymio implementation. All one has to do is use an instance of the `Thymio` class inside the `src/thymio.py` file.\n",
    "\n",
    "The cell below will connect and disconnect with the Thymio. Note that the Thymio's LEDs are turned off when connected to avoid disturbing vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to Thymio failed!\n",
      "Unable to connect to the Thymio! Is it connected? Is Thymio suite open?\n"
     ]
    }
   ],
   "source": [
    "from src import thymio\n",
    "\n",
    "try:\n",
    "    th = thymio.Thymio()\n",
    "    print(\"Connected to Thymio\")\n",
    "    # Example usage:\n",
    "    th.process_command(command=model.MotorSpeed(left=0, right=0))\n",
    "    sensor_data = th.read_sensor_data()\n",
    "    # Disconnect\n",
    "    th.stop()\n",
    "except:\n",
    "    print(\"Unable to connect to the Thymio! Is it connected? Is Thymio suite open?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Path planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Global navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Local navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Integrating everything together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] https://docs.opencv.org/4.x/d5/dae/tutorial_aruco_detection.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('thymio')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5cb2b05fda319fcaf36b2b811f9866acb85f635c74b98cc7029a7ace995d9f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
